% mnras_template.tex
%
% LaTeX template for creating an MNRAS paper
%
% v3.0 released 14 May 2015
% (version numbers match those of mnras.cls)
%
% Copyright (C) Royal Astronomical Society 2015
% Authors:
% Keith T. Smith (Royal Astronomical Society)

% Change log
%
% v3.0 May 2015
%    Renamed to match the new package name
%    Version number matches mnras.cls
%    A few minor tweaks to wording
% v1.0 September 2013
%    Beta testing only - never publicly released
%    First version: a simple (ish) template for creating an MNRAS paper

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Basic setup. Most papers should leave these options alone.
\documentclass[a4paper,fleqn,usenatbib]{mnras}

% MNRAS is set in Times font. If you don't have this installed (most LaTeX
% installations will be fine) or prefer the old Computer Modern fonts, comment
% out the following line
%\usepackage{newtxtext,newtxmath}
% Depending on your LaTeX fonts installation, you might get better results with one of these:
%\usepackage{mathptmx}
%\usepackage{txfonts}

% Use vector fonts, so it zooms properly in on-screen viewing software
% Don't change these lines unless you know what you are doing
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}


%%%%% AUTHORS - PLACE YOUR OWN PACKAGES HERE %%%%%

% Only include extra packages if you really need them. Common packages are:
\usepackage{graphicx}	% Including figure files
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}	% Extra maths symbols

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% AUTHORS - PLACE YOUR OWN COMMANDS HERE %%%%%

% Please keep new commands to a minimum, and use \newcommand not \def to avoid
% overwriting existing commands. Example:
%\newcommand{\pcm}{\,cm$^{-2}$}	% per cm-squared

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%% TITLE PAGE %%%%%%%%%%%%%%%%%%%

% Title of the paper, and the short title which is used in the headers.
% Keep the title short and informative.
\title[Predicting extragalactic distance errors]{Predicting extragalactic distance errors using Bayesian inference in multi-measurement catalogs}

% The list of authors, and the short list which is used in the headers.
% If you need two or more lines of authors, add an extra line using \newauthor
\author[G. Chaparro-Molano et al.]{Germ\'an Chaparro-Molano$^{1}$\thanks{E-mail: gchaparrom@ecci.edu.co},
Juan Carlos Cuervo,
Oscar Alberto Restrepo Gait\'an$^{1,2}$, \newauthor
Sergio Torres Arzay\'{u}s$^{3}$
\\
% List of institutions
$^{1}$Vicerrector\'ia de Investigaci\'on, Universidad ECCI, Bogot\'a, Colombia\\
$^{2}$Radio Astronomy Instrumentation Group, Universidad de Chile, Santiago de Chile, Chile\\
$^{3}$Centro Internacional de F\'isica, Bogot\'a, Colombia
}

% These dates will be filled out by the publisher
\date{Accepted XXX. Received YYY; in original form ZZZ}

% Enter the current year, for the copyright statements etc.
\pubyear{2018}

% Don't change these lines
\begin{document}
\label{firstpage}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}
\maketitle

% Abstract of the paper
\begin{abstract}
We propose two methods for robustly estimating extragalactic distance errors in multi-measurement catalogs. We seek to improve upon more commonly used frequentist propagation-of-error methods, as they fail to explain both the scatter between different measurements and the effects of skewness in the metric distance probability distribution. For individual galaxies, the most transparent way to assess the variance of redshift independent distances is to directly sample the posterior probability distribution obtained from the mixture of reported measurements. However, sampling the posterior can be cumbersome for catalog-wide precision cosmology applications. We compare the performance of frequentist methods versus our proposed measures for estimating the true variance of the metric distance probability distribution. We provide pre-computed distance error data tables for galaxies in 3 catalogs: NED-D, HyperLEDA, and Cosmicflows-3. From a Markov Chain Monte Carlo-based analysis of systematic and random effects in the computed errors, we develop a predictive Bayesian model for the variance of distance errors for Tully-Fisher relation (TF) derived distances in NED-D. We validate this model with a Bayesian $p$-value computed using the Freeman-Tukey discrepancy measure as a posterior predictive check. We are then able to predict distance errors for 884 galaxies in the NED-D catalog which do not report TF distance modulus errors. Our goal is that our pre-computed errors are used in catalog-wide applications that require acknowledging the true variance of extragalactic distance measurements.
\end{abstract}

% Select between one and six entries from the list of approved keywords.
% Don't make up new ones.
\begin{keywords}
methods: data analysis -- methods: statistical -- galaxies: distances -- galaxies: statistics -- catalogues -- astronomical data bases: miscellaneous
\end{keywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% BODY OF PAPER %%%%%%%%%%%%%%%%%%

\section{Introduction}


Understanding the uncertainties in redshift-independent extragalactic distance measurements is absolutely necessary before reporting statistically sound conclusions regarding the structure of the local universe \citep{void,locunivcf,nongauss,6df,localunipv,said,gg3500}, large scale structure \citep{anishub,gallargescale,morphanis,tecciencia,bayesh}, and events like transient gravitational wave detections \citep{gwgallist}. Hubble constant estimations have been using increasingly sophisticated statistical tools for primary distance determination methods, such as SNIa \citep{ridsn,unity,hubsn2018}, Cepheids \citet{hubngc} or both \citep{riess}. Although most estimates of the Hubble constant use Cepheid calibration for calibrating secondary methods \citep{hubunc,huborig,hub2010}, \citet{noceph} have explored changes in Hubble constant estimation using the Tully-Fisher relation (TF) without Cepheid calibration. Secondary methods for extragalactic distance determination like the TF relation, or the Fundamental Plane (FP) have recently become more precise thanks to increasing volumes of data from surveys like 6dF \citep{6df}  and  2MASS \citep{2mass,tf07dist} together with Spitzer data \citep{sorce}, along with improved statistical methods \citep{precisetf}. \\

As of 2018, three multi-measurement catalogs including a substantial amount of redshift-independent extragalactic distance measurements have been released: HyperLEDA \citep{hyperleda}, NED-D \citep{ned07,ned}, and Cosmicflows-3 \citep{cosmicflows}. HyperLEDA includes a homogenized catalog for extragalactic distances in the nearby universe, with 12866 distance measurements for 518 galaxies to date. NED-D is the NASA/IPAC Extragalactic Distance catalog of Redshift-Independent Distances, which compiles 326850 distance measurements for 183062 galaxies in its 2018 version. Here, $\sim1800$ galaxies ($\sim1$\%) have more than 13 distance measurements, and $~180$ galaxies ($\sim0.1$\%) have distance measurements using more than 6 different methods. Cosmicflows-3 is the most up-to-date catalog, which reports distance measurements for 10616 galaxies (all of which include errors) using up to four distance determination methods, calibrated with supernova luminosities. However, unlike HyperLEDA or NED-D, Cosmicflows-3 only reports the latest distance measurement for each method. In HyperLEDA, NED-D and Cosmicflows-3 errors are reported as one standard deviation from the reported distance modulus. Treatment of errors for combining distance moduli across methods or across measurements is suggested by \citet{ned07} and \citet{cosmicflows} to be based on weighted estimates such as the uncertainty of the weighted mean, albeit with caution partly due to the heterogeneous origin of the compiled data and partly due to Malmquist bias. In the case of NED-D, this is additionally complicated by the fact that many errors are not reported or are reported as zero. In fact, the TF relation method has the largest number of galaxies with non-reported distance modulus errors (884 to date). Even though extragalactic distances measured using the TF relation were originally reported to have a relative error in distance modulus of $10-20$\% \citep{tforig}, we consider that this conservative estimate can be improved upon by using a predictive model based on the distance error of galaxies that use the same distance determination method. This requires a robust estimation of the variance of extragalactic distances based on the available data.\\

For many galaxies in all three catalogs, the random error for each distance modulus measurement $\epsilon_i$ (for $i=1,...,N$, for $N$ distance measurements per galaxy) is not representative of the scatter across measurements, even when considering the same method for determining distances. In addition, distance modulus distributions for each measurement (which are assumed to be Gaussian) are transformed to log-normal distributions in metric distance space. This can introduce a significant bias in peculiar velocity studies for large-scale structure studies \citep{lognormal}. We improve upon previous methods by robustly estimating the underlying variance across measurements and distance determination methods. To do this, we measure the half-distance between the 84th and 16th percentiles, and the median absolute deviation of the bootstrap-sampled posterior probability distribution of each extragalactic distance \citep{chaparro18}. We compare our results to other more commonly used frequentist methods, such as the weighted estimates mentioned above, and we produce pre-computed data tables for the three catalogs mentioned above. We then perform a Markov Chain Monte Carlo analysis of the systematics and randomness of the computed errors. From this analysis we build predictive Bayesian models for the estimation of errors and evaluate them by performing posterior predictive checks using a discrepancy measure-derived Bayesian ``$p$-value'' \citep{gelmanppd}. Furthermore, we make predictions for the 884 galaxies in the NED-D catalog whose distances were measured using the TF relation but have non-reported errors, and compare our predictions to HyperLEDA-estimated TF errors. Inference based on Bayesian posterior predictive checks has been advocated for in \citet{gelman2003} and \citet{ppcinf}.\\

We organize this paper as follows. In Section~\ref{sec:post} we talk about the posterior distribution of distance for individual galaxies and set up methods for measuring its variance. In Section~\ref{sec:comp} we make a comparison between the proposed variance estimation methods, and in Section~\ref{sec:predbay} we propose and evaluate predictive Bayesian models for two robust methods of error estimation, and we summarize our work in the Conclusions section. The appendix includes a description and brief analysis of extragalactic distance error data tables pre-computed with the methods described in this paper for the HyperLEDA, Cosmicflows-3 and NED-D catalogs.

\section{Probability distribution estimation for extragalactic distances}
\label{sec:post} 
 
The best approach to consider the effects of random and systematic errors in catalog-wide, multi-method distance analyses is to directly sample the posterior probability distribution of each extragalactic distance. This can be achieved by drawing distance modulus bootstrap samples from $P(\mu)$, which is the unweighted mixture of normal distributions corresponding to each distance modulus measurement $\mu_i$,
\[\mu\sim\sum_i^N \mathcal{N}(\mu_i,\epsilon_i^2)\ ,\]
and then converting to metric distance,
\[D=10^{\frac{\mu}{5}+1}\ .\]
Therefore,
\[D_G\sim\sum_i^N\mathrm{lognormal}(M_i,\sigma_{M_i}^2)\ .\]
Here $M_i=\ln D_i$ and $\sigma_{M_i}=\epsilon_i\cdot\ln10$.\\

However, this method is not very efficient for a standardized treatment of errors. It is more convenient to treat each extragalactic metric distance $D_G$ as a normal random variable with a single-valued $\sigma_D$ as a measure of the uncertainty in the estimation of an extragalactic distance,
\[D_G\sim \mathcal{N}(D,\sigma_D^2)\]
For this reason we compare four methods for estimating the $D,\,\sigma_D$ pair. Two of these methods (H, M) use robust measures of the posterior distribution of each extragalactic distance, and the other two (P, Q) use measures based on propagation of errors.

\subsection{Estimating the variance of $P(D_G)$}
\label{sec:meth} 

Method H takes $D$ as the median of the posterior and $\sigma_D$ as the half-distance (H) between the 84th and 16th percentiles of the posterior. We consider this to be the method which most faithfully measures the variance regardless of the shape of the posterior distribution. Method M takes $D$ as the median of the posterior and $\sigma_D$ as the median absolute deviation (MAD) of the posterior. This method is better suited for avoiding the effects of outliers. Method P consists on calculating $D$ from the weighted mean distance modulus $\bar{\mu}^*$ with weights $w_i=\epsilon_i^{-2}$. $\sigma_D$ is calculated by propagation (P) of measurement errors  i.e. from the uncertainty of the weighted mean \citep{cosmicflows},
\begin{equation}
\sigma_D^P=0.461\,\bar{D}^*\,\left(\sum_i^Nw_i\right)^{-1/2} \ ,
\end{equation}
Method P does not take into account the scatter in distance measurements for single galaxies, which is why method Q calculates $D$ same as method P, but $\sigma_D$ is calculated as the sum in quadrature (Q) of the propagated uncertainty of the weighted mean and the propagated unbiased weighted sample variance $\sigma_D^*$:
\begin{equation}
\sigma_D^Q=\left[ \left(\sigma_D^P\right)^2+\Big(\sigma_D^*\Big)^2\right]^{1/2} \ .
\end{equation}
Here $\sigma^*_D$ is calculated as  \citep{wstdev},
\begin{equation}
\sigma^*_D=0.461\,\bar{D}^*\,\sqrt{\frac{N}{N-1.5}\frac{\sum_i^Nw_i(\mu_i-\bar{\mu}^*)^2}{\sum_i^Nw_i}\vphantom{\Biggl(}}\ .
\end{equation}
If the non-robust P and Q methods are representative of the variance of the posterior, they should yield similar results as the H method. Next section shows that this is not the case.

\section{Comparison of variance estimation methods}
\label{sec:comp} 


Even though our analysis for error estimation can be used to combine distance measurements using different methods for single galaxies, we think that due to method-intrinsic systematics it is more appropriate to separate the analysis by method. A full discussion of our error estimation method applied to multi-method measurements in the HyperLEDA, NED-D and Cosmicflows-3 is given in the appendix. A live, Binder-compatible repository for this work is located at \texttt{https://github.com/saint-germain/errorprediction}. Without loss of generality, we focus on galaxies whose distances have been measured using the Tully-Fisher method in the NED-D catalog because it is the method with the largest number of galaxies without reported measurement errors (884) in the database. From here on, when we mention distance measurements in the NED-D catalog, we will be excluding from our analysis measurements that require the target redshift to calculate the distance, as indicated in the \texttt{redshift (z)} field. \\

For galaxies with a number of distance measurements between 2 and 5  (Fig.~\ref{fig:NED}, left) , errors estimated with the the quadrature (Q), and median absolute deviation (M) methods show a linear trend with similar slopes that over-predict the variance with respect to the half 84th-16th percentile distance (H) method, whereas the propagation (P) method tends to under-predict the errors. Furthermore, errors estimated using the Q method show a larger dispersion around the linear trend than the H and M methods. Fig.~\ref{fig:NED} (right) shows that the P and Q methods underpredict errors for galaxies with more than 5 distance measurements. The central limit theorem indicates that as the number of measurements increases, the behavior of the distance errors should settle toward being normally distributed around the correlation trend. Fig.~\ref{fig:comp} shows that for a small but representative sample of galaxies with more than 7 distance measurements, the center and variance of the posterior distribution of each extragalactic distance is best explained using the H method, whereas the less robust P and Q methods under-predict the variance. The M method also under-predicts the variance because it is a robust method, and thus not as sensitive to outliers as methods P and Q, as seen in the case of NGC 1558 in Fig.~\ref{fig:comp}. For the more symmetrical posterior distribution of UGC 12792, the M and Q methods predict the same center and variance. Fig.~\ref{fig:hqp-qm} shows that the Q and P methods under-predict distance errors for galaxies with more than 5 TF distance measurements. On the other hand, method Q under-predicts distance errors with respect to the M method, which again shows a tighter linear correlation due to the robustness of the M measure. The general correlation between distance and distance error (Figs.~\ref{fig:NED} and \ref{fig:hqp-qm}) means that there is a strong systematic component in the variance of $P(D_G)$, which is expected from the distance modulus to metric distance conversion. To improve visualization, only errors for galaxies with more than 5 TF distance measurements are shown in Figs.~\ref{fig:hqp-qm}, \ref{fig:ee}, and \ref{fig:predl1}.
\begin{figure*}
	\includegraphics[scale=0.69]{Nlow.png}
	\includegraphics[scale=0.69]{Nhigh.png}
    \caption{Estimated extragalactic distance errors vs. median extragalactic distance for galaxies with $N<6$ (left) and $N>5$ (right)  redshift-independent distance measurements in NED-D according to the H, M, Q, P error models  (explained in the text), showing a linear regression and confidence intervals computed using the \texttt{seaborn.regplot} Python function.}
    \label{fig:NED}
\end{figure*}


\begin{figure*}

	\includegraphics[scale=0.7]{comp}
    \caption{Comparison of four examples of extragalactic distance posterior distribution draws (10000 per measurement) and modeled distributions for UGC 06667, NGC 1558, UGC 08186, and UGC 12792 using the Tully-Fisher Method for distance determination in NED-D. The methods used for approximating the posterior distribution (H, M, P, and Q) are described in the text. }
    \label{fig:comp}
\end{figure*}

\begin{figure*}

	\includegraphics[scale=0.69]{hqp.png}
	\includegraphics[scale=0.69]{qm.png}
    \caption{Estimated extragalactic distance errors vs. median extragalactic distance  for galaxies with more than 5 TF distance measurements in NED-D according to the H, Q, P (left) and Q, M (right) error models, showing a linear regression and confidence intervals computed using the \texttt{seaborn.regplot} Python function.}
    \label{fig:hqp-qm}
\end{figure*}


\begin{figure*}

	\includegraphics[scale=0.7]{ee.png}
    \caption{Variance of distance error estimates vs. estimated extragalactic distance errors as determined by the H and M methods, showing a linear regression and confidence intervals computed using the \texttt{seaborn.regplot} Python function. }
    \label{fig:ee}
\end{figure*}

Given that each $\sigma_D$ calculated using the H and M methods is obtained from many realizations from the posterior distribution of extragalactic distances, it is also possible to calculate its variance as the half-distance between the 84th and 16th percentile of bootstrap $\sigma_D$ realizations. Fig.~\ref{fig:ee} shows that the variance of the estimated error is proportional to the error for the H and M methods. This will be relevant in Section~\ref{sec:predbay} when we construct a predictive model for non-reported errors.

\section{Predictive Bayesian Models for TF missing errors}
\label{sec:predbay} 

As seen in Fig.~\ref{fig:hqp-qm}, TF distance errors estimated using the robust methods H and M grow in a roughly linear fashion with distance, but are randomly distributed around this trend line. For this reason we try out several Bayesian models in order to be able to predict missing distance errors. For this, we use the \texttt{emcee} affine invariant Markov Chain Monte Carlo (MCMC) ensemble sampler \citep{emcee}. Recently, \texttt{emcee} has been proved to be useful in obtaining probabilistic estimations for photometric redshifts \citet{photred1,photred2}. Since we want to be able to predict non-reported errors, our model selection is based on posterior predictive checks, i.e. we rely on models that can create synthetic datasets similar to the original dataset \citep{gelmanppd}. This allows us to reproduce the original variance of the error (Fig.~\ref{fig:ee}. Many Bayesian analyses often do not use posterior predictive checks, like in the work of \citet{propprob2018} and \citet{bayesh}, where they used \texttt{emcee} for posterior sampling, and using Bayesian and Akaike Information Criteria along with Bayes factors for model assessment, but without attempting to reproduce the original variance of the data. This is also the case in other Bayesian tools like Linmix  \citep{gmastro}, which is widely used in astronomy for approximating unobserved data.  \\

First we assume that for any galaxy $j$ the distance error $\sigma_{Dj}$ is a random normal variable, with variance $\sigma_{\sigma j}$ and mean $\hat{\sigma}_{Dj}$, 
\begin{equation}
P(\sigma_{Dj}|\hat{\sigma}_{Dj},\sigma_{\sigma j})=\mathcal{N}(\hat{\sigma}_{Dj},\sigma_{\sigma j}^2)\ .
	\label{eq:prob}
\end{equation}
Our likelihood function is the joint probability that each of the $\sigma_D=\{\sigma_{Dj}\}$ in the original dataset of $m$ galaxies is generated by the above probability,  
\begin{equation}
 P(\sigma_{D}|\hat{\sigma}_{D},\sigma_{\sigma})=\prod_j^mP(\sigma_{Dj}|\hat{\sigma}_{Dj},\sigma_{\sigma j})
\end{equation}
We want to test the hypothesis mentioned above that all errors and their variances $(\hat{\sigma}_D=\{\hat{\sigma}_{Dj}\},\ \sigma_\sigma=\{\sigma_{\sigma j}\})$ can be estimated from a single model depending on the extragalactic distances $D_G=\{D_{Gj}\}$ and a set of distance-independent parameters $\pmb{\theta}$. Thus the likelihood can be expressed as,
\[P(\sigma_D|D_G,\pmb{\theta})=\prod_j^mP(\sigma_{Dj}|D_{Gj},\pmb{\theta})\ .\]
Following Bayes' theorem we can compute the posterior probability up to a constant,
\begin{equation}
P(\pmb{\theta}|D_G,\sigma_D)\propto P(\pmb{\theta})P(\sigma_D|D_G,\pmb{\theta})\ .
	\label{eq:ppd}
\end{equation}
Due to the simplicity of the models used here, we will only use conservative (flat) priors. From our analysis of Fig.~\ref{fig:ee}, all our models take $\sigma_\sigma=f\hat{\sigma}_D$. This error variance scale factor $f$ is therefore one of the parameters in $\pmb{\theta}$. On the other hand, our models will differ by the proposed functional forms of $\hat{\sigma}_D(D_G,\pmb{\theta})$.\\

We obtain a computationally credible sampling of the posterior probability by removing the burn-in steps of the random walk according to the autocorrelation time. We can then create synthetic datasets by drawing a parameter sample $\pmb{\theta}_k$ from the posterior and using it to draw from the likelihood to create a new dataset, i.e. drawing new $\sigma_{Dj}$ from the probability distribution for all galaxies in the original dataset using equation~\ref{eq:prob}. We then assess the validity of the model by comparing synthetic data with the observed (i.e. original) data. This comparison is done by using a discrepancy measure $\mathcal{D}(\sigma_D|\pmb{\theta}_k)$ between data and model-derived expected values for the same data $e=\{e_j(\pmb{\theta}_k)\}$, where $\theta_k$ is drawn from the posterior distribution and $\sigma_D$ can be the observed errors or the model-generated synthetic errors. The discrepancy can be calculated using a statistic like $\chi^2$ \citep{chi2ms,otherdisc}, but here we will work with the Freeman-Tukey discrepancy since it is weight independent \citep{bishopft,brooks}, 
\[\mathcal{D}(\sigma_D|\pmb{\theta}_k)=\sum_j^m(\sqrt{\sigma_{Dj}\vphantom{e_j(\pmb{\theta}_k)}}-\sqrt{e_j(\pmb{\theta}_k)})^2\]
For each parameter draw $k$, it is possible to compare the simulated discrepancy with the observed discrepancy. If the model is representative of the data, then for many parameter draws, the simulated and observed discrepancies should be similar. We can then calculate a Bayesian ``$p$-value'' as the ratio of ``draws when the observed discrepancies are larger than the synthetic discrepancies'' to ``total draws''. If this Bayesian $p$-value is too close to 0 or to 1 we can reject the model, otherwise we cannot reject the model, as it is generating synthetic data that is similar to the original data. This is better visualized using a discrepancy plot, where for each draw $k$, a synthetic discrepancy is paired with its corresponding observed discrepancy. If the discrepancy points are roughly equally distributed about the $\mathcal{D}_\mathrm{obs}=\mathcal{D}_\mathrm{sym}$ line, then we cannot reject the model. We expect that galaxies with the largest number of measurements are sampling more completely the ``true'' distribution of the distance. Therefore we expect that if we set an increasing limit on the minimum number of measurements per galaxy on the dataset that goes in the model, the Bayesian $p$-value will improve.

\subsection{Bayesian Quadrature Model}
\label{sec:bqm} 

Our first model is based on the hypothesis that there are are distinct systematic and random contributions to the distance measurement error, both of which are normally distributed. For this reason they are added in quadrature, 
\begin{equation}
\sigma_D^2=\sigma_s^2+\sigma_r^2\ .
	\label{eq:bayq}
\end{equation}
Here $\sigma_r$ is a random (constant) error and the systematic error is modeled allowing for scale factor ($s$) and zero setting ($a$) errors, i.e.  $\sigma_s=sD+a$, as Fig.~\ref{fig:hqp-qm} suggests.  We set our prior to be symmetrical around $\sigma_r=0$ in order to better visualize its behavior near this point, so
\begin{equation}
P(s,a,\sigma_r,f)\propto\left\{
\begin{aligned}
1,\ \ \ \ &\mathrm{if}\ \ \ 0<s<1\ \mathrm{and}\\
& \ \ \ \ \  0<a<10\ \mathrm{Mpc}\ \mathrm{and}\\
&-10<\sigma_r<10\ \mathrm{Mpc}\ \mathrm{and}\\
& \ \ \ \ \  0<f<1\\
0,\ \ \ \ &\ \mathrm{otherwise.}
\end{aligned}
\right.
	\label{eq:priorq}
\end{equation}
We now use \texttt{emcee} to sample the posterior over the parameter set $\pmb{\theta}=(s,\sigma_r,f,a)$ using 100 walkers and 20000 steps ($t_\mathrm{autocorr} \lesssim 90$ steps). According to the discrepancy plot in Fig.~\ref{fig:discq} (left), this model is able to replicate method H errors for the 29 galaxies with $N>25$ measurements (812 measurements in total). The corner plot showing the posterior sampling made by \texttt{emcee} is shown in Fig.~\ref{fig:cornerq}, which shows that the systematic scale factor error is $s=0.24_{-0.03}^{+0.03}$, the random error component is $\sigma_r=-0.004_{-1.296}^{+1.294}$ Mpc, the error variance scale factor is $f=0.24_{-0.03}^{+0.04}$, and the zero offset systematic error is $a=0.43_{-0.34}^{+0.56}$\ Mpc. From the large variance in the marginalized posterior distribution for $\sigma_r$ and $a$, we see that there is a significant degeneracy between those parameters. However, it should be noted that the marginalized posterior distribution of $\sigma_r$ is symmetric around zero (because of its own degeneracy), while the distribution of $a$ can only take positive values. The working distance range and overall fitting of this model is shown in Fig.~\ref{fig:drawsq} (left), where method H errors corresponding to galaxies with more than 25 TF distance measurements are plotted along the expected values $e=\{e_j(\pmb{\theta}_k)\}$ for parameter sets $\pmb{\theta}_k$ drawn from the posterior probability distribution. 
\begin{figure*}
	\includegraphics[scale=0.69]{discq.png}
	\includegraphics[scale=0.69]{discq2.png}
    \caption{Discrepancy plot for the Bayesian quadrature model (equation~\ref{eq:bayq}) based on errors estimated using method H for $N_\mathrm{TF}>23,24,25$ (left) and using method M for $N_\mathrm{TF}>12,13$ (right).}
    \label{fig:discq}
\end{figure*}
\begin{figure*}
	\includegraphics[scale=0.7]{cornerq}
    \caption{Corner plot showing the \texttt{emcee} sampling of the posterior probability distribution (equation \ref{eq:ppd}) for the quadrature Bayesian model parameters $\pmb{\theta}=(s,\sigma_r,f,a)$ based on errors estimated using method H for galaxies with more than 25 TF distance measurements. The dashed lines indicate the 16th, 50th, and 84th percentile of the marginalized distribution of each parameter (shown at the top of each column), and the blue solid lines indicate the mean. This plot was made using the \texttt{corner} Python module.}
    \label{fig:cornerq}
\end{figure*}
\begin{figure*}
	\includegraphics[scale=0.7]{cornerq2}
    \caption{Corner plot showing the \texttt{emcee} sampling of the posterior probability distribution (equation \ref{eq:ppd}) for the quadrature Bayesian model parameters $\pmb{\theta}=(s,\sigma_r,f,a)$ based on errors estimated using method M for galaxies with more than 13 TF distance measurements. The dashed lines indicate the 16th, 50th, and 84th percentile of the marginalized distribution of each parameter (shown at the top of each column), and the blue solid lines indicate the mean. This plot was made using the \texttt{corner} Python module.}
    \label{fig:cornerq2}
\end{figure*}
\begin{figure*}
	\includegraphics[scale=0.69]{drawsq}
	\includegraphics[scale=0.69]{drawsq2}
    \caption{Projection of parameter set samples from the posterior probability distribution of the Bayesian quadrature model onto the  $\sigma_D$ vs. $D_G$ scatter plot for errors estimated using method H for galaxies with more than 25 TF distance measurements (left) and using method M for galaxies with more than 13 TF distance measurements (right).}
    \label{fig:drawsq}
\end{figure*}
Now we sample the posterior distribution for the Bayesian quadrature model with method M errors using \texttt{emcee} with 100 walkers and 20000 steps s ($t_\mathrm{autocorr} \lesssim 50$ steps). The discrepancy plot for method M errors in Fig.~\ref{fig:discq} (right) shows that the quadrature model also replicates method M errors, but for the 727 galaxies with more than 13 measurements (12947 measurements in total). Fig.~\ref{fig:cornerq2}, shows that $s=0.142_{-0.003}^{+0.003}$, $\sigma_r=0.004_{-0.201}^{+0.201}$ Mpc, $f=0.228_{-0.006}^{+0.007}$, and $a=0.52_{-0.06}^{+0.06}$ Mpc. The random error is so low that the model draws are almost indistinguishable from straight lines in Fig~\ref{fig:drawsq} (right). Additionally, and just as for the quadrature model for H errors above, the symmetry of the marginalized posterior distribution of $\sigma_r$ leads us to set this parameter to zero in our next model in order to improve numerical stability.



\subsection{Bayesian Linear Model}
\label{sec:blm}
In Section~\ref{sec:bqm} above we conclude that we can ignore the random error component in equation~\ref{eq:bayq} in order to work with a simpler, numerically stable, linear model that only considers a systematic error with scale factor and zero setting error components,
\begin{equation}
\sigma_D=\sigma_s=sD+a\ .
	\label{eq:bayl}
\end{equation}
We also update our prior considering that the quadratic model yielded lower values for the zero setting error $a$ than previously considered in equation~\ref{eq:priorq},
\begin{equation}
P(s,a,f)\propto\left\{
\begin{aligned}
1,\ \ \ \ &\mathrm{if}\ \ \ 0<s<1\ \mathrm{and}\\
& \ \ \ \ \  0<a<2\ \mathrm{Mpc}\ \mathrm{and}\\
& \ \ \ \ \  0<f<1\\
0,\ \ \ \ &\ \mathrm{otherwise.}
\end{aligned}
\right.
\end{equation}
We use \texttt{emcee} to sample the posterior over $\pmb{\theta}=(s,a,f)$ using 100 walkers and 10000 steps ($t_\mathrm{autocorr} < 50$ steps) for the linear Bayesian model applied to H errors. The discrepancy plot (Fig.~\ref{fig:discl}, left) shows a significant improvement over the quadratic model, as it shows an acceptable Bayesian $p$-value for the 473 galaxies with $N>15$ measurements (9259 in total), whereas the quadratic model replicated errors only for galaxies with $N>25$ measurements. Fig.~\ref{fig:cornerl}, shows that for the linear Bayesian model using H errors for galaxies with more than 15 measurements, $s=0.200_{-0.006}^{+0.006}$, $a=0.76_{-0.12}^{+0.13}$ Mpc, and $f=0.256_{-0.009}^{+0.009}$.
\begin{figure*}
	\includegraphics[scale=0.69]{discl.png}
	\includegraphics[scale=0.69]{discl2.png}
    \caption{Discrepancy plot for the Bayesian linear model (equation~\ref{eq:bayl}) based on errors estimated using method H for $N_\mathrm{TF}>13,14,15$ (left) and using method M for $N_\mathrm{TF}>11,12,13$ (right). }
    \label{fig:discl}
\end{figure*}
\begin{figure*}
	\includegraphics[scale=0.7]{cornerl}
    \caption{Corner plot showing the \texttt{emcee} sampling of the posterior probability distribution (equation \ref{eq:ppd}) for the linear Bayesian model parameters $\pmb{\theta}=(s,a,f)$ based on errors estimated using method H for galaxies with more than 15 TF distance measurements. The dashed lines indicate the 16th, 50th, and 84th percentile of the marginalized distribution of each parameter (shown at the top of each column), and the blue solid lines indicate the mean. This plot was made using the \texttt{corner} Python module.}
    \label{fig:cornerl}
\end{figure*}
We sample the posterior for the linear model applied to M errors using \texttt{emcee} with 100 walkers and 10000 steps ($t_\mathrm{autocorr} < 50$ steps). Fig.~\ref{fig:discl2} (right) shows the corresponding discrepancy plot, which does not show a significant improvement of the linear over the quadratic model for M errors, as it also works for galaxies with $N>13$ measurements. This happens because the sampling of the posterior for the quadratic model (Fig.~\ref{fig:cornerq2}) does not show a degeneracy between $\sigma_r$ and $a$, and also because the marginalized posterior distribution for $\sigma r$ is a near-zero distribution with a variance of $0.2$ Mpc. The parameters according the the linear model and data are $s=0.142_{-0.003}^{+0.003}$, $a=0.53_{-0.06}^{+0.06}$ Mpc, and $f=0.228_{-0.006}^{+0.006}$, as shown in Fig.~\ref{fig:cornerl2}. 

\begin{figure*}
	\includegraphics[scale=0.7]{cornerl2}
    \caption{Corner plot showing the \texttt{emcee} sampling of the posterior probability distribution (equation \ref{eq:ppd}) for the linear Bayesian model parameters $\pmb{\theta}=(s,a,f)$ based on errors estimated using method M for galaxies with more than 13 TF distance measurements. The dashed lines indicate the 16th, 50th, and 84th percentile of the marginalized distribution of each parameter (shown at the top of each column), and the blue solid lines indicate the mean. This plot was made using the \texttt{corner} Python module.}
    \label{fig:cornerl2}
\end{figure*}
\begin{figure*}
	\includegraphics[scale=0.69]{drawsl}
	\includegraphics[scale=0.69]{drawsl2}
    \caption{Projection of parameter set samples from the posterior probability distribution of the Bayesian linear model onto the $\sigma_D$ vs. $D_G$ scatter plot for errors estimated using method H for galaxies with more than 15 TF distance measurements (left) and using method M for galaxies with more than 13 TF distance measurements (right).}
    \label{fig:drawsl}
\end{figure*}
\begin{figure*}
	\includegraphics[scale=0.7]{drawsee}
    \caption{Projection of parameter set samples from the posterior probability distribution of the Bayesian linear model onto the $\sigma_\sigma$ vs. $\sigma_D$ scatter plot for errors estimated using methods H and M for galaxies with more than 15 and 13 TF distance measurements, respectively.}
    \label{fig:drawsee}
\end{figure*}
\subsection{Predictions for missing errors}
\label{sec:pred} 
Our linear Bayesian model is able to predict the intrinsic variance of H and M errors by modeling them as systematic errors, with zero setting and scale factor error components. The lower limit of distance measurements for which the model works for H and M errors, is 15 and 13, respectively. Fig.~\ref{fig:drawsl} shows the linear model draws for H and M errors, for which the working range is approximately $D_G\in[3,140]$ Mpc. We also show in Fig.~\ref{fig:drawsee} that the model draws for $f$ the scale parameter for the variance of $\sigma_D$ fit the bootstrap variance of H and M errors well. Given that galaxies with the lower limit of observations quoted above are not intrinsically different to other galaxies in this range, we use the posterior predictive distribution of the linear Bayesian model for predicting errors for the 884 galaxies in NED-D for which all TF measurements lack a reported error. Fig.~\ref{fig:predl1} shows synthetic errors generated from the posterior predictive distribution for the $\sigma_D$ linear model, along with the expected values of $\sigma_D$ using the median of the posterior probability distribution in equation~\ref{eq:ppd}, and the $D_G$ vs. $\sigma_D$ points for galaxies with more than 5 TF distance measurements (for contrast) for methods H and M, respectively. The median expected values are only drawn for points within the predictive range of each model, and synthetic predicted errors for galaxies outside of this range are plotted in black. The distance was calculated using the median of the reported distances whenever there was more than one TF distance measurement. Additionally, Fig.~\ref{fig:predhl1}  shows a good agreement between predicted errors for galaxies with non-reported TF errors and estimated errors in the HyperLEDA catalog. The predicted errors were computed from the posterior predictive distribution of the model using NED-D estimated errors.\\

The HyperLEDA catalog has distance measurements for 4224 galaxies, of which 1064 galaxies have reported measurements without errors. Of these, 203 have TF distance measurements. We can create synthetic errors for these using our Bayesian predictive models for H and M TF errors. Fig.~\ref{fig:predhl1} (left) shows that predicted H errors are somewhat higher than those estimated for HyperLEDA, although acceptably within the range. Fig.~\ref{fig:predhl1} (right) shows that predicted M errors are even closes to the HyperLEDA M error estimates. This is an independent validation of our linear Bayesian model for predicting TF distance errors, and its capacity to estimate systematic effects of the TF distance determination method.\\

This predictive model may work for other distance determination methods, but a cursory overview of methods which require error prediction due to missing errors (e.g. TRGB, CMD, Eclipsing Binary, Red Clump, PNLF, SZ effect, Brightest Stars, Horizontal Branch in NED-D) suggests that such attempts need to be evaluated in a case-by-case basis. For instance, in NED-D, Fundamental Plane (FP) measurements are by far the most numerous ($\sim130k$ galaxies), but only 28 of those have more than 3 FP distance measurements. We attempted to create a model similar to what we did for TF, but we were only able to find a working predictive model (i.e. yielding a good Bayesian $p$-value) for the 16 galaxies with more than 4 distance measurements. The comparatively low number of galaxies for which this model works makes us wary of predicting FP errors, therefore we do not report these results.
\begin{figure*}
	\includegraphics[scale=0.69]{predl1.png}
	\includegraphics[scale=0.69]{predl2.png}
    \caption{Synthetic H-method (left) and M-Method (right) $\sigma_D$ and their median expected values vs. $D_G$ for the 884 galaxies in NED-D for which no TF distance measurements report an error, generated using the corresponding Bayesian linear model. Predicted errors for galaxies outside of the working distance range of the model are plotted in black. H (left) and M (right) errors for galaxies with more than 5 TF measurements are also plotted for comparison.}
    \label{fig:predl1}
\end{figure*}

\begin{figure*}
	\includegraphics[scale=0.69]{predhl1.png}
	\includegraphics[scale=0.69]{predhl2.png}
    \caption{Synthetic H-method (left) and M-method (right) $\sigma_D$ and their median expected values vs. $D_G$ for the 71 galaxies in HyperLEDA for which no TF distance measurements report an error, generated using the corresponding Bayesian linear model. Predicted errors for galaxies outside of the working distance range of the model are plotted in black. H errors for galaxies with more than 2 distance measurements are also plotted for comparison.}
    \label{fig:predhl1}
\end{figure*}


\section{Conclusions}

We propose two methods for robustly estimating the uncertainty in extragalactic distances in multi-measurement, multi-method catalogs from bootstrap-sampled posterior probability distributions. In method H we compute the half-distance between the 84th and 16th percentiles, and in method M we estimate the error with the median absolute deviation. Method H gives errors that represent most faithfully the variance of the distance probability distribution, whereas traditional frequentist propagation-of-error methods under-perform at estimating the true variance of these distributions. Whenever a specific application requires to give less weight to outdated or possibly wrong outliers, errors computed using method M should be used.\\

We produce error tables using the robust (H, M) and frequentist (P, Q) methods for NED-D, HyperLEDA, and Cosmicflows-3, along with a distance estimated using the median of the bootstrap-sampled distance distribution. These tables can be found in the repository for this paper, located at \texttt{http://github.com/saint-germain/errorprediction}. A description and analysis for each catalog can be found in the appendices. We consider that these error tables should be a fundamental tool for future precision cosmology, catalog-wide studies, as it should be possible to quote errors according to the method that the reader considers most relevant for specific applications.\\

We create a Bayesian predictive model for TF distance errors for H and M errors based on an assumption-free analysis of the systematic and random components in distance errors. We performed a posterior predictive check in the form of the computation of a Bayesian $p$-value based on simulated vs. observed discrepancies measured with the Freeman-Tukey statistic, thus achieving a model which can reproduce the intrinsic variance of distance errors along with the systematic zero-setting and scale factor components in the errors. Similar Bayesian predictive methods can be set up in principle for other distance determination methods but with caveats, as models work better for methods for which there are many galaxies with a high number of distance measurements.\\ 

Finally, we want to advocate for the widespread use of discrepancy plots and their derived Bayesian $p$-values for  Bayesian model checking in astronomy, as inference is based on the model's ability to reproduce the original distribution of the data and not on a relative comparison to other models.



\section*{Acknowledgements}

The authors would like to thank O. L. Ram\'irez-Su\'arez and J. E. Forero-Romero for their valuable input during the early stages of this work. This research has made use of the NASA/IPAC Extragalactic Database (NED), which is operated by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the National Aeronautics and Space Administration.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%

% The best way to enter references is to use BibTeX:

\bibliographystyle{mnras}
\bibliography{savedrecs} % if your bibtex file is called example.bib


% Alternatively you could enter them by hand, like this:
% This method is tedious and prone to error if you have lots of references
%\begin{thebibliography}{99}
%\bibitem[\protect\citeauthoryear{Author}{2012}]{Author2012}
%Author A.~N., 2013, Journal of Improbable Astronomy, 1, 1
%\bibitem[\protect\citeauthoryear{Others}{2013}]{Others2013}
%Others S., 2012, Journal of Interesting Stuff, 17, 198
%\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% APPENDICES %%%%%%%%%%%%%%%%%%%%%

\appendix

\section{Estimation of errors for HyperLEDA}
We estimated errors for the HyperLEDA redshift-independent extragalactic distance database using the methods described in Section~\ref{sec:comp} across all distance determination methods, ignoring measurements with no reported errors. As expected from our analysis of TF errors in NED-D, errors calculated with methods P, Q, and M overpredict the error with respect to the H method for galaxies with a low number of distance measurements ($N=2$), as shown in Fig.~\ref{fig:HLlow}. Fig.~\ref{fig:HLhigh} shos that for galaxies with a higher number of distance measurements, the P method significantly underpredicts the error with respect to the other methods. Even though the H and Q methods show a similar trend, the variance of Q errors around this trend is higher than for H methods. Errors obtained with method M are lower, due to the method's intrinsic robustness. These estimations are reported in the file called \texttt{hl\_bootstrap\_results.csv} in the repository. The fields are:
\begin{itemize}
\item \texttt{objname} - Object name according to the HyperLEDA database.
\item \texttt{j2000} - J2000 coordinates.
\item \texttt{meas} - Number of distance measurements.
\item \texttt{D (Mpc)} - This is the median of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{Dmin (Mpc)} - This is the 16th percentile of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{Dmin (Mpc)} - This is the 84th percentile of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{H (Mpc)} - Error estimated using the H method (\texttt{Dmax-Dmin})/2.
\item \texttt{M (Mpc)} - Error estimated using the M method. 
\item \texttt{P (Mpc)} - Error estimated using the P method. 
\item \texttt{Q (Mpc)} - Error estimated using the Q method. 
\end{itemize}
\begin{figure*}
	\includegraphics[scale=0.69]{HLlow.png}
	\includegraphics[scale=0.69]{HLhigh.png}
    \caption{Estimated extragalactic distance errors vs. median extragalactic distance for galaxies with $N=2$ (left) and $N>2$ (right) redshift-independent distance measurements in HyperLEDA according to the H, M, Q, P error models, showing a linear regression and confidence intervals computed using the \texttt{seaborn.regplot} Python function.}
    \label{fig:HLlow}
\end{figure*}


\section{Estimation of errors for Cosmicflows-3}
The Extragalactic Distance Database (EDD) of Cosmicflows-3, which has the most up-to-date calibrated distance measurements using the TF, FP, SNIa methods for more than 17000 galaxies. We estimated errros for the approximately 10\% of them which have more than one reported distance, using the methods described in Section~\ref{sec:comp}. Fig.~\ref{fig:low} shows that the P method, which is the suggested method in \citet{cosmicflows}, overpredicts errors with respect to the H method for galaxies with 2 distance measurements, as was the case for the errors of HyperLEDA. For galaxies with more than 2 distance measurements, Fig.~\ref{fig:CF3high} the P method underpredicts the errors with respect to the H method. Even though the M, H, and Q methods show a similar trend with distance, the Q method has a significantly larger scatter around this trend. We compiled the estimated errors in a companion table to the Cosmicflows-3 EDD database and in a similar format, in the file called \texttt{cf3\_bootstrap\_results.csv} in the repository for this work. The fields in this table are:
\begin{itemize}
\item \texttt{pgc} - Principal Galaxies Catalog ID number.
\item \texttt{Name} - Object name according to the Cosmicflows-3 database, where available.
\item \texttt{meas} - Number of distance measurements.
\item \texttt{D (Mpc)} - This is the median of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{Dmin (Mpc)} - This is the 16th percentile of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{Dmin (Mpc)} - This is the 84th percentile of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{H (Mpc)} - Error estimated using the H method (\texttt{Dmax-Dmin})/2.
\item \texttt{M (Mpc)} - Error estimated using the M method. 
\item \texttt{P (Mpc)} - Error estimated using the P method. 
\item \texttt{Q (Mpc)} - Error estimated using the Q method. 
\end{itemize}
\begin{figure*}
	\includegraphics[scale=0.69]{CF3low.png}
	\includegraphics[scale=0.69]{CF3high.png}
    \caption{Estimated extragalactic distance errors vs. median extragalactic distance for galaxies with $N=2$ (left) and $N>2$ (right) redshift-independent distance measurements in Cosmicflows-3 according to the H, M, Q, P error models, showing a linear regression and confidence intervals computed using the \texttt{seaborn.regplot} Python function.}
    \label{fig:CF3low}
\end{figure*}

\section{Estimation of errors for NED-D}
The 2018 version of the NASA/IPAC extragalactic distance catalog NED-D has $\sim300000$ redshift-independent distance measurements with reported errors for $\sim180000$ galaxies. We estimated the errors for the $\sim16000$ galaxies with more than one distance measurement. The database of errors for NED-D is in the file called \texttt{ned\_bootstrap\_results.csv} and contains the information corresponding to the following fields:
\begin{itemize}
\item \texttt{Galaxy ID} - Object name according to the Cosmicflows-3 database, where available.
\item \texttt{meas} - Number of distance measurements.
\item \texttt{D (Mpc)} - This is the median of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{Dmin (Mpc)} - This is the 16th percentile of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{Dmin (Mpc)} - This is the 84th percentile of the posterior distribution of the corresponding extragalactic distance.
\item \texttt{H (Mpc)} - Error estimated using the H method (\texttt{Dmax-Dmin})/2.
\item \texttt{M (Mpc)} - Error estimated using the M method. 
\item \texttt{P (Mpc)} - Error estimated using the P method. 
\item \texttt{Q (Mpc)} - Error estimated using the Q method. 
\end{itemize}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\citep[e.g.][]{photred1}.
%Figures are referred to as e.g. Fig.~\ref{fig:example_figure}, and tables as
%e.g. Table~\ref{tab:example_table}.
% Example table
%\begin{table}
%	\centering
%	\caption{This is an example table. Captions appear above each table.
%	Remember to define the quantities, symbols and units used.}
%	\label{tab:example_table}
%	\begin{tabular}{lccr} % four columns, alignment for each
%		\hline
%		A & B & C & D\\
%		\hline
%		1 & 2 & 3 & 4\\
%		2 & 4 & 6 & 8\\
%		3 & 5 & 7 & 9\\
%		\hline
%	\end{tabular}
%\end{table}



% Don't change these lines
\bsp	% typesetting comment
\label{lastpage}
\end{document}

% End of mnras_template.tex